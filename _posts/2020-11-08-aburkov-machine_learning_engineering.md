---
title:  "游닀 machine learning engineering"
layout: post
date:   2020-11-08
notes: true
author: jartigag
image: /assets/images/posts/XXX.png
tag:
- notas
- libro
- machine learning
mastodonReplies: https://mastodon.social/@jartigag/XXXXXXXXXXXXXXXXXX
twitterReplies: https://twitter.com/jartigag/status/XXXXXXXXXXXXXXXXXXX
---

Con esta entrada empiezo una nueva categor칤a de posts que voy a llamar "notas".
No son m치s que apuntes que he hecho mientras le칤a alg칰n libro o ve칤a alguna charla.

En este caso, salen de un libro sobre ingenier칤a de aprendizaje autom치tico, que es un tema al que le quer칤a echar un ojo.
Me pic칩 la curiosidad despu칠s de haber desplegado mi [TFM sobre clustering](https://github.com/jartigag/tfm-clustering) en un entorno real
como buenamente supe, poniendo el foco en evitar cualquier complicaci칩n que amenazara poder presentarlo en la defensa del trabajo.
Una vez superado ese objetivo, encontr칠 este libro, que se distribuye bajo el principio ["read-first, buy-later"](https://twitter.com/burkov/status/1324765117846851584),
y quise saber c칩mo dicen que hay que hacer esto.

Es un tema sobre el que me parece que no hay mucho publicado, por cierto.
No sobre teor칤a de machine learning, qu칠 tipos hay y c칩mo funcionan los algoritmos m치s conocidos, claro. Eso est치 m치s que machacado.
Me refiero a poner a funcionar el aprendizaje autom치tico en el mundo real, a lo ingenieril del asunto.
Este libro trata de esos aspectos pr치cticos que suelen descubrirse solo con la experiencia.

Lo que hice fue recopilar los borradores de los cap칤tulos, que se ofrec칤an [sueltos en la web](http://www.mlebook.com/wiki/doku.php#released_drafts_of_the_chapters),
revisarlos todos por encima y leer en detalle los que me interesaban m치s.
Para quedarme con las ideas que expon칤a, escrib칤 estas cuatro cosas, pero eso no quiere decir que sean las m치s importantes del libro.
Ni siquiera que est칠 de acuerdo con ellas o que deban tomarse como referencia. Solo las comparto como la s칤ntesis que saqu칠 de aqu칤 en el momento en el que lo le칤.
Si alguien m치s encuentra algo 칰til en ella, yo que me alegro :)

## /칤ndice:

<!-- vim-markdown-toc GFM -->

* [游닀 Machine Learning Engineering](#-machine-learning-engineering)
    * [Cu치ndo usar aprendizaje autom치tico](#cu치ndo-usar-aprendizaje-autom치tico)
    * [Cu치ndo no utilizar aprendizaje autom치tico](#cu치ndo-no-utilizar-aprendizaje-autom치tico)
    * [El ciclo de vida de un proyecto de aprendizaje autom치tico](#el-ciclo-de-vida-de-un-proyecto-de-aprendizaje-autom치tico)
    * [Propiedades de un buen modelo](#propiedades-de-un-buen-modelo)
    * [Problemas comunes con los datos](#problemas-comunes-con-los-datos)
    * [Los datos de calidad](#los-datos-de-calidad)
    * [Generaci칩n de datos artificiales ("data augmentation")](#generaci칩n-de-datos-artificiales-data-augmentation)
    * [Selecci칩n de caracter칤sticas](#selecci칩n-de-caracter칤sticas)
    * [Reducci칩n de dimensionalidad](#reducci칩n-de-dimensionalidad)
    * [Escalar las caracter칤sticas](#escalar-las-caracter칤sticas)
    * [Buenas pr치cticas de la ingenier칤a de datos ("feature engineering")](#buenas-pr치cticas-de-la-ingenier칤a-de-datos-feature-engineering)
    * [Servir, monitorizar y mantener el modelo](#servir-monitorizar-y-mantener-el-modelo)
        * [Propiedades del entorno de ejecuci칩n en el que se sirve el modelo](#propiedades-del-entorno-de-ejecuci칩n-en-el-que-se-sirve-el-modelo)
        * [Servir un modelo en el mundo real: lidiar con errores](#servir-un-modelo-en-el-mundo-real-lidiar-con-errores)

<!-- vim-markdown-toc -->

# 游닀 [Machine Learning Engineering](http://www.mlebook.com/wiki/doku.php)

[A. Burkov](https://ca.linkedin.com/in/andriyburkov) (Director de Data Science y Machine Learning Team Leader en Gartner)

## Cu치ndo usar aprendizaje autom치tico

* Cuando el problema es demasiado complejo para programarlo (enti칠ndase como "codificarlo en t칠rminos de algoritmos tradicionales").

    ej.: detecci칩n de spam, concesi칩n de pr칠stamos

* Cuando el problema est치 cambiando constantemente.

    ej.: scraping

* Cuando es un problema de percepci칩n.

    ej.: reconocimiento de voz / imagen / v칤deo ("en el pasado, se usaban filtros").

* Cuando es un fen칩meno "poco estudiado".

    "No se ha estudiado en profundidad cient칤ficamente, pero sus ejemplos son observables". ej.: opciones de medicaci칩n personalizadas para salud mental, predicciones a partir de logs de sistemas o redes inform치ticas complejos.

* Cuando el problema tiene un objetivo simple.

    ej.: decisiones de s칤 o no, un 칰nico n칰mero

* Cuando es efectivo en coste.

    Considerando el coste de: recoger y preparar datos, entrenar el modelo, construir y poner en funcionamiento la infraestructura para sevir y monitorizar el modelo y, por 칰ltimo, mantenerlo.

## Cu치ndo no utilizar aprendizaje autom치tico

* Cuando cada acci칩n del sistema o cada decisi칩n que tome debe ser explicable.
* Cuando cada cambio en el comportamiento del sistema (respecto a su comportamiento pasado) debe ser explicable.
* Cuando el coste de un error que cometa el sistema es demasiado alto.
* Cuando se pueda resolver el problema utilizando desarrollo tradicional de software con un coste menor.
* Cuando una heur칤stica simple ser칤a suficiente para que funcionara razonablemente bien.
* Cuando no puedes conseguir una cantidad de ejemplos suficiente para representar todos los resultados del fen칩meno.

## El ciclo de vida de un proyecto de aprendizaje autom치tico

![]({{site.baseurl}}/assets/images/posts/ml_project_life_cycle.png)

## Propiedades de un buen modelo

* Respeta tanto las especificaciones de las entradas y las salidas como los requisitos de rendimiento.
* Beneficia a la organizaci칩n (en t칠rminos de reducci칩n de costes, incremento de ventas o beneficio).
* Ayuda al usuario (en t칠rminos de productividad, *engagement* y sentimiento).
* Es cient칤ficamente riguroso.

Al definir el objetivo de un proyecto de aprendizaje autom치tico, deben definirse:
* Las entradas y salidas del modelo
* La funci칩n de coste
* La m칠trica de rendimiento

## Problemas comunes con los datos

* Alto coste
* Mala calidad
* Ruido
* Sesgo:
    * Sesgo de selecci칩n: tendencia a restringir la elecci칩n de fuentes de datos a aquellas que son convenientes, f치ciles de obtener y/o efectivas en coste.
    * Sesgo de auto-selecci칩n: obtener los datos de fuentes que los proporcionan "voluntariamente" (ej.: encuestas).
    * Sesgo de variables omitidas: entre las caracter칤sticas extra칤das de los datos falta alguna que es necesaria para una predicci칩n precisa (ej.: prediciendo la fidelidad del cliente, aparece un competidor y eso no estaba caracterizado en tu modelo).
    * Sesgo de muestreo: la distribuci칩n de ejemplos usada para el entrenamiento no refleja la distribuci칩n de las entradas que recibir치 el modelo en producci칩n.
    * Sesgo de prejuicio: ej.: fotos en las que los ricos son blancos y los pobres son negros, word embedding que predice que programmer - man + woman = homemaker.
    * Distorsi칩n sistem치tica de los valores: es un problema relativo al dispositivo que hace las medidas u observaciones.
    * Sesgo del experimentador: tendencia a confirmar las hip칩tesis que tiene uno mismo a priori.
    * Sesgo de etiquetado: se da cuando un proceso o individuo sesgado asigna las etiquetas.
* Bajo poder de predicci칩n: ocurre cuando los datos no contienen suficiente informaci칩n de la que aprender o cuando el modelo no es suficientemente expresivo. Es dif칤cil de anticipar. Sugerencias: ingeniar tantas caracter칤sticas como sea posible (usa tu creatividad!), considerar fuentes de datos indirectas para enriquecer los vectores de caracter칤sticas.
* Filtraci칩n de datos: afecta a varias fases del ciclo de vida del aprendizaje autom치tico. Se define como "la introduci칩n no intencionada de informaci칩n sobre el objetivo que no deber칤a estar disponible".

![]({{site.baseurl}}/assets/images/posts/data_leakage.png)

## Los datos de calidad

* Contienen informaci칩n suficiente que se puede usar para modelar
* Reflejan las entradas reales que ver치 el modelo en producci칩n.
* Son lo menos sesgados posible.
* No son un resultado del propio modelo.
* Tienen etiquetas consistentes.
* Est치n en una cantidad lo suficientemente grande como para generalizar a partir de ellos.

## Generaci칩n de datos artificiales ("data augmentation")

Estrategia para conseguir m치s datos etiquetados sin necesidad de procesos de etiquetado adicionales.

El caso m치s efectivo es el aplicado a im치genes. Consiste en aplicar operaciones simples como recortar o reflejar.

## Selecci칩n de caracter칤sticas

No todas las caracter칤sticas son igualmente importantes para un problema dado. Si estimamos la importancia de las caracter칤sticas, podremos mantener s칩lo las m치s importantes. Esto nos permitir치 ahorrar tiempo, cargar m치s ejemplos en memoria y mejorar la calidad del modelo.

T칠cnicas de selecci칩n de caracter칤sticas:
* Descartar las colas largas.
* Boruta: este m칠todo envolvedor (wrapper), popular en Kaggle, entrena modelos de random forest de manera iterativa y les aplica test estad칤sticos para identificar las caracter칤sticas como importantes o no importantes. Recu칠rdese que el meta-algoritmo random forest usa 치rboles de decisi칩n bas치ndose en la idea del bagging (empaquetado).
* Regulaci칩n Lasso (L1): mejora la generalizaci칩n del modelo permitiendo que el algoritmo de aprendizaje autom치tico aprenda a ignorar algunas caracter칤sticas.
* Espec칤ficas de la tarea: ej.: eliminar palabras no significativas.

Las buenas caracter칤sticas tienen alto poder de predicci칩n, pueden computarse r치pidamente, son fiables y est치n incorreladas. Tambi칠n son f치ciles de entender y mantener.

## Reducci칩n de dimensionalidad

* Reducci칩n de dimensionalidad r치pida: PCA (An치lisis de Componentes Principales).
* Reducci칩n de dimensionalidad para visualizaci칩n: UMAP (Aproximaci칩n y Proyecci칩n M칰ltiple Uniforme), auto-encoder.

## Escalar las caracter칤sticas

* Normalizaci칩n: en un rango [0,1]. Cuidado con los outliers (posible soluci칩n: windsorizaci칩n).
* Estandarizaci칩n: reescalar los valores de las caracter칤sticas de manera que tengan las propiedades de una distribuci칩n normal est치ndar (media 0, desviaci칩n t칤pica 1). Es decir, calcular sus valores Z aplicando (x-avg)/stdev

## Buenas pr치cticas de la ingenier칤a de datos ("feature engineering")

B치sicas:
* Escalar las caracter칤sticas antes de entrenar el modelo.
* Documentar y almacenar las caracter칤sticas en *schema files* o *feature stores* (esto en grandes organizaciones que reutilizan caracter칤sticas a lo largo de m칰ltiples equipos y proyectos).
```
feature{name:"height", type:float, min:..,max:..,.. zeroes:F, undefined:F, popularity:1.0},
feature{name:"color red", type:binary, zeroes:T, undefined:F, popularity:1.0}
```

M치s:
* Generar muchas caracter칤sticas simples.
* Reutilizar sistemas legacy.
* Usar IDs como caracter칤sticas cuando es necesario..  
    Esto es contraintuitivo, pero permite cear un modelo que tiene un comportamiento en un caso general y otro en casos distintos (ej.: localizaci칩n general/espec칤ficas).
* ..Pero reducir la cardinalidad cuando sea posible.  
    T칠cnicas: agrupar valores similares, agrupar colas largas, eliminar caracter칤sticas con mucha cardinalidad
* Loggear los valores de las caracter칤sticas (o al menos una muestra aleatoria)  
    Cuando se trabaje en una nueva versi칩n del modelo, estos valores ser치n 칰tiles para controlar la calidad de los datos de entrenamiento (los valores de las caracter칤sticas en producci칩n deben ser los mismos que en los datos de entrenamiento).

## Servir, monitorizar y mantener el modelo

### Propiedades del entorno de ejecuci칩n en el que se sirve el modelo

* Seguridad y correcci칩n (al interaccionar con los usuarios).
* Facilidad de despliegue.
* Garant칤as de la validez del modelo -> tests tanto end-to-end como de confianza (calcular una m칠trica de rendimiento y establecer un rango de valores aceptables).
* Facilidad de recuperaci칩n -> rolling back
* Evitar desvirtuaciones entre el entorno de entrenamiento y el de producci칩n (evitar utilizar dos bases de c칩digo distintas)
* Evitar bucles de retroalimentaci칩n ocultos. Hay dos tipos:
    * El modelo B extrae caracter칤sticas de la salida del modelo A, sin saber que el modelo A utiliza la del modelo B.
    * Un solo modelo involucrado. ej.: acciones del usuario en un sistema anti-spam (el usuario no va a la carpeta de spam para marcar que algunos mensajes no son spam). Esto ser칤an datos sesgados (skewed data), porque influenciamos en el fen칩meno sobre el que queremos aprender. Para evitarlo, podr칤a marcarse un peque침o % de ejemplos como "retenidos" y mostr치rselos al usuario sin aplicar el modelo de antemano. Entonces solo estos ejempos retenidos se usar칤an como ejemplos adicionales de entrenamiento.

### Servir un modelo en el mundo real: lidiar con errores

La visibilidad del error es un factor importante a la hora de decidir si se esconde o no y c칩mo hacerlo. ej.: alertas no cr칤ticas. En esta situaci칩n, puede ser preferible optimizar el modelo para la precisi칩n, a costa de mantener la sensibilidad razonablemente alta.

Precision (predicci칩n positiva) = TP / TP+FP

Recall (sensibilidad o tasa de TP) = TP / TP+FN
